## 2.4 Worker执行内容

### 1. main方法

```scala
def main(argStrings: Array[String]) {
    // 置处理未被捕获的异常处理器
    Thread.setDefaultUncaughtExceptionHandler(new SparkUncaughtExceptionHandler(
      exitOnUncaughtException = false))
    Utils.initDaemon(log)
    val conf = new SparkConf
    // 解析参数，并未sparkConf设置默认参数(默认的参数来自于$SPARK_HOME/conf/spark-defaults.con文件)
    val args = new WorkerArguments(argStrings, conf)
    // 创建RpcEnv并启动RpcEndpoint
    val rpcEnv = startRpcEnvAndEndpoint(args.host, args.port, args.webUiPort, args.cores,
      args.memory, args.masters, args.workDir, conf = conf)
    // 如果开启了external shuffle服务, 当请求启动多个worker时，我们只能启动第一个，剩下的都会失败，更多详情请查看：SPARK-20989.
    val externalShuffleServiceEnabled = conf.getBoolean("spark.shuffle.service.enabled", false)
    val sparkWorkerInstances = scala.sys.env.getOrElse("SPARK_WORKER_INSTANCES", "1").toInt
    require(externalShuffleServiceEnabled == false || sparkWorkerInstances <= 1,
    rpcEnv.awaitTermination()
  }
```

### 2. startRpcEnvAndEndpoint方法

```scala
def startRpcEnvAndEndpoint(
      host: String,
      port: Int,
      webUiPort: Int,
      cores: Int,
      memory: Int,
      masterUrls: Array[String],
      workDir: String,
      workerNumber: Option[Int] = None,
      conf: SparkConf = new SparkConf): RpcEnv = {

    // 获取系统名字
    val systemName = SYSTEM_NAME + workerNumber.map(_.toString).getOrElse("")
    // 创建一个SecurityManager、RpcEnv，为创建RpcEndPoint做准备
    val securityMgr = new SecurityManager(conf)
    val rpcEnv = RpcEnv.create(systemName, host, port, conf, securityMgr)
    // 从spark://host:port类似的地址提取(host,port)
    val masterAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))
    // 与master节点相同，调用org.apache.spark.rpc.netty.NettyRpcEnv#setupEndpoint方法进行NettyRpcEndpointRef的创建
    rpcEnv.setupEndpoint(ENDPOINT_NAME, new Worker(rpcEnv, webUiPort, cores, memory,
      masterAddresses, ENDPOINT_NAME, workDir, conf, securityMgr))
    rpcEnv
  }
```

### 3. Worker中重写RpcEndpoint中的方法

1. ###### onstart()

   1. 启动externalShuffleService

   2. 创建WorkerWebUI

   3. 向master进行注册

      1. 通过从脚本传入的master参数创建newDaemonCachedThreadPool，该线程池的大小与master的数量相同

      2. 线程池中的每个线程通过master的地址与end point name获取masterEndPoint

      3. 向master发送注册信息

         ```
         消息内容：RegisterWorker( workerId, host, port, self, cores, memory, workerWebUiUrl, masterEndpoint.address)
         ```

2. ###### receive()

   1. 如果接受到的是**RegisterWorkerResponse**，则会进行接收到注册响应的逻辑处理

      1. 更改master的相关属性

         ```
         activeMasterUrl: String = masterRef.address.toSparkURL
         activeMasterWebUiUrl : String = uiUrl
         masterAddressToConnect: Option[RpcAddress] = Some(masterAddress)
         master: Option[RpcEndpointRef] = Some(masterRef)
         connected = true
         ```

      2. 通过newDaemonSingleThreadScheduledExecutor守护线程池每**15**秒发送一次心跳

      3. 如果开启了**spark.worker.cleanup.enabled**，则每**30**分钟进行一次工作空间的清理

      4. 向master发送最新的worker状态

         > ```
         > WorkerLatestState(workerId, execs.toList, drivers.keys.toSeq)
         > ```